# LLM äº¤äº’æ—¥å¿—æ ¼å¼è¯´æ˜

æœ¬æ–‡æ¡£æè¿°äº† StoryCrew é¡¹ç›®ä¸­å¢å¼ºçš„ LLM äº¤äº’æ—¥å¿—åŠŸèƒ½ã€‚

## åŠŸèƒ½æ¦‚è¿°

å¢å¼ºçš„ `LoggingInterceptor` ç°åœ¨ä¼šè®°å½•æ¯æ¬¡ LLM è°ƒç”¨çš„å®Œæ•´ä¿¡æ¯ï¼š

1. **Request (å‘é€ç»™ LLM)**
   - å®Œæ•´çš„ prompt å†…å®¹
   - ä¼°ç®—çš„ token æ•°é‡
   - æ¶ˆæ¯ç»“æ„ï¼ˆå¦‚æœæœ‰å¤šä¸ªæ¶ˆæ¯ï¼‰

2. **Response (ä» LLM æ”¶åˆ°)**
   - å®Œæ•´çš„ response å†…å®¹
   - å®é™…çš„ token ä½¿ç”¨é‡ï¼ˆå¦‚æœ API æä¾›ï¼‰
   - ä¼°ç®—çš„ token æ•°é‡
   - æˆæœ¬ä¼°ç®—

## æ—¥å¿—æ ¼å¼

### 1. è¯·æ±‚æ—¥å¿—

```
[LLM INTERCEPTOR] Request #N
[LLM INTERCEPTOR] Request URL: https://api.example.com/v1/chat/completions
[LLM INTERCEPTOR] Request Method: POST
[LLM REQUEST] ğŸ“¤ Request contains M messages
[LLM REQUEST] Message 1 [system] (1,234 tokens est.):
[LLM REQUEST] You are a helpful assistant...
[LLM REQUEST] Message 2 [user] (5,678 tokens est.):
[LLM REQUEST] Please help me with...
```

### 2. å“åº”æ—¥å¿—

```
[LLM TOKENS] ğŸ“Š Actual Token Usage (from API):
[LLM TOKENS]   Input (prompt):  6,912 tokens
[LLM TOKENS]   Output (completion): 1,234 tokens
[LLM TOKENS]   Total: 8,146 tokens
[LLM TOKENS]   Est. Cost: $0.0055
[LLM RESPONSE] ğŸ“¥ Response Content (2,500 tokens est.):
[LLM RESPONSE] Here's the response from the LLM...
```

## Token ä¼°ç®—ç®—æ³•

ç”±äºæ— æ³•ç›´æ¥è®¿é—® LLM çš„ tokenizerï¼Œæˆ‘ä»¬ä½¿ç”¨å¯å‘å¼ç®—æ³•ä¼°ç®— token æ•°é‡ï¼š

```python
# ä¸­æ–‡å­—ç¬¦ï¼šçº¦ 2 å­—ç¬¦/token
# è‹±æ–‡å­—ç¬¦ï¼šçº¦ 4 å­—ç¬¦/token

chinese_chars = count(0x4e00 <= c <= 0x9fff)  # CJK Unicode èŒƒå›´
other_chars = total_length - chinese_chars

estimated_tokens = (chinese_chars / 2) + (other_chars / 4)
```

**æ³¨æ„ï¼š**
- è¿™åªæ˜¯ç²—ç•¥ä¼°ç®—
- å®é™… token æ•°é‡å–å†³äºå…·ä½“çš„ tokenizer
- æ—¥å¿—ä¸­ä¼šåŒæ—¶æ˜¾ç¤ºä¼°ç®—å€¼ï¼ˆest.ï¼‰å’Œ API è¿”å›çš„å®é™…å€¼ï¼ˆå¦‚æœæœ‰ï¼‰

## æ—¥å¿—çº§åˆ«

- **INFO**: ä¸»è¦çš„è¯·æ±‚/å“åº”å†…å®¹
- **WARNING**: æ— æ³•æå–æŸäº›ä¿¡æ¯ï¼ˆå¦‚ request bodyï¼‰
- **DEBUG**: é¢å¤–çš„è°ƒè¯•ä¿¡æ¯ï¼ˆå¦‚æ— æ³•æå– token usageï¼‰

## å†…å®¹æˆªæ–­ç­–ç•¥

ä¸ºé¿å…æ—¥å¿—è¿‡å¤§ï¼Œé•¿å†…å®¹ä¼šè¢«æˆªæ–­ï¼š

- **Request messages**: æœ€å¤šæ˜¾ç¤º 1000 å­—ç¬¦
- **Request prompt**: æœ€å¤šæ˜¾ç¤º 2000 å­—ç¬¦
- **Response content**: æœ€å¤šæ˜¾ç¤º 5000 å­—ç¬¦
- è¶…è¿‡é™åˆ¶æ—¶ä¼šæ˜¾ç¤º `[truncated, total N chars]`

## ä½¿ç”¨åœºæ™¯

### 1. æˆæœ¬åˆ†æ

é€šè¿‡æ—¥å¿—ä¸­çš„ token ä¿¡æ¯ï¼Œå¯ä»¥ï¼š
- è¿½è¸ªæ¯ä¸ªä»»åŠ¡çš„ token æ¶ˆè€—
- è®¡ç®—æ€»ä½“æˆæœ¬
- ä¼˜åŒ– prompt ä»¥å‡å°‘ token ä½¿ç”¨

### 2. è°ƒè¯•

å®Œæ•´çš„è¯·æ±‚/å“åº”æ—¥å¿—å¸®åŠ©ï¼š
- æ£€æŸ¥å‘é€ç»™ LLM çš„ prompt æ˜¯å¦æ­£ç¡®
- éªŒè¯ LLM è¿”å›çš„å†…å®¹æ ¼å¼
- è¯Šæ–­ API è°ƒç”¨é—®é¢˜

### 3. æ€§èƒ½ä¼˜åŒ–

é€šè¿‡åˆ†ææ—¥å¿—å¯ä»¥ï¼š
- è¯†åˆ«å“ªäº›ä»»åŠ¡æ¶ˆè€—æœ€å¤š tokens
- ä¼˜åŒ–ä»»åŠ¡æè¿°ä»¥å‡å°‘é‡å¤å†…å®¹
- è°ƒæ•´ max_tokens å‚æ•°

## æ—¥å¿—æ–‡ä»¶ä½ç½®

æ—¥å¿—æ–‡ä»¶é»˜è®¤ä¿å­˜åœ¨ `logs/` ç›®å½•ï¼š
- å¼€å‘ç¯å¢ƒï¼š`logs/storycrew.log`
- æµ‹è¯•ç¯å¢ƒï¼š`logs/test_*.log`

## ç¤ºä¾‹æ—¥å¿—ç‰‡æ®µ

```
================================================================================
[LLM INTERCEPTOR] Request #1
[LLM INTERCEPTOR] Request URL: https://api.openai.com/v1/chat/completions
[LLM INTERCEPTOR] Request Method: POST
[LLM INTERCEPTOR] Response Status: 200
[LLM REQUEST] ğŸ“¤ Request contains 3 messages
[LLM REQUEST] Message 1 [system] (234 tokens est.):
[LLM REQUEST] You are a creative writer specializing in romance novels...
[LLM REQUEST] Message 2 [user] (5,678 tokens est.):
[LLM REQUEST] Please write chapter 1 with the following outline... [truncated, total 12000 chars]
[LLM REQUEST] Message 3 [assistant] (1,234 tokens est.):
[LLM REQUEST] [Previous conversation context]
[LLM TOKENS] ğŸ“Š Actual Token Usage (from API):
[LLM TOKENS]   Input (prompt):  7,146 tokens
[LLM TOKENS]   Output (completion): 2,345 tokens
[LLM TOKENS]   Total: 9,491 tokens
[LLM TOKENS]   Est. Cost: $0.0073
[LLM RESPONSE] ğŸ“¥ Response Content (3,456 tokens est.):
[LLM RESPONSE] Chapter 1
[LLM RESPONSE] The morning sun streamed through the windows... [truncated, total 15000 chars]
================================================================================
```

## é…ç½®

å¦‚éœ€è°ƒæ•´æ—¥å¿—è¯¦ç»†ç¨‹åº¦ï¼Œå¯ä»¥ä¿®æ”¹ `LoggingInterceptor` ç±»ä¸­çš„æˆªæ–­é™åˆ¶ï¼š

```python
# crew.py - LoggingInterceptor.__call__()

# å½“å‰é™åˆ¶ï¼š
# - Request message preview: 1000 chars
# - Request prompt preview: 2000 chars
# - Response content preview: 5000 chars
```

## æ•…éšœæ’é™¤

### é—®é¢˜ï¼šçœ‹ä¸åˆ° request æ—¥å¿—

**å¯èƒ½åŸå› ï¼š**
- Request å¯¹è±¡ä¸åŒ…å« `body` æˆ– `data` å±æ€§
- Request body ä¸æ˜¯ JSON æ ¼å¼

**è§£å†³æ–¹æ³•ï¼š**
- æ£€æŸ¥æ—¥å¿—ä¸­çš„ WARNING ä¿¡æ¯
- ç¡®è®¤ LLM provider æ˜¯å¦æ”¯æŒ interceptor

### é—®é¢˜ï¼štoken ä¼°ç®—ä¸å‡†ç¡®

**è¯´æ˜ï¼š**
- ä¼°ç®—å€¼ä¸å®é™…å€¼å¯èƒ½æœ‰ Â±20% çš„è¯¯å·®
- è¿™å¯¹æˆæœ¬ä¼°ç®—æ¥è¯´æ˜¯å¯ä»¥æ¥å—çš„
- å¦‚éœ€ç²¾ç¡®å€¼ï¼Œä¾èµ– API è¿”å›çš„ `usage` å­—æ®µ

### é—®é¢˜ï¼šæ—¥å¿—æ–‡ä»¶è¿‡å¤§

**è§£å†³æ–¹æ³•ï¼š**
- ä½¿ç”¨æ—¥å¿—è½®è½¬ï¼ˆlog rotationï¼‰
- è°ƒæ•´æ—¥å¿—çº§åˆ«ï¼ˆåªè®°å½• INFO åŠä»¥ä¸Šï¼‰
- å‡å°‘æˆªæ–­é™åˆ¶ï¼ˆä½†ä¼šä¸¢å¤±è¯¦ç»†ä¿¡æ¯ï¼‰
